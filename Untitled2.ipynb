{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on training set\n",
      "train.dat\n",
      "1\n",
      "train_labels\n",
      "train_docs\n",
      "LOL\n",
      "Working on  test file\n",
      "Building CSR matrix\n",
      "50000\n",
      "8425213\n",
      "Calculate Cosine Similarity\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e85754e618ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Calculate Cosine Similarity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m \u001b[0msimilarities_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Finally, caluclating nearest neighbours'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhrumil/anaconda2/lib/python2.7/site-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhrumil/anaconda2/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhrumil/anaconda2/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dhrumil/anaconda2/lib/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    538\u001b[0m                                     maxval=nnz)\n\u001b[1;32m    539\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import norm\n",
    "from scipy import linalg\n",
    "import re\n",
    "import copy\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import metrics\n",
    "from porter2stemmer import Porter2Stemmer\n",
    "stemmer = Porter2Stemmer()\n",
    "#print(stemmer.stem('conspicuous'))si\n",
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents,\n",
    "    each of which is a list of word/terms in the document.\n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    # Remove all ratings\n",
    "    for d in docs:\n",
    "        #d = d[1:]\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "    print nrows\n",
    "    print ncols\n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        #d = d[1:]\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "\n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "\n",
    "    return mat\n",
    "\n",
    "#@profile\n",
    "def filterLen(docs, minlen):\n",
    "    return [ [t for t in d if len(t) >= minlen ] for d in docs ]\n",
    "\n",
    "def stemDoc(docs):\n",
    "    \"\"\" automatically removes suffixes (and in some cases prefixes) in order to\n",
    "    find the root word or stem of a given word\n",
    "    \"\"\"\n",
    "    return [ [stemmer.stem(t) for t in d ] for d in docs]\n",
    "\n",
    "def csr_idf(mat, copy=False, **kargs):\n",
    "    r\"\"\" Scale a CSR matrix by idf.\n",
    "    Returns scaling factors as dict. If copy is True,\n",
    "    returns scaled matrix and scaling factors.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # document frequency\n",
    "    df = defaultdict(int)\n",
    "    for i in ind:\n",
    "        df[i] += 1\n",
    "    # inverse document frequency\n",
    "    for k,v in df.items():\n",
    "        df[k] = np.log(nrows / float(v))  ## df turns to idf - reusing memory\n",
    "    # scale by idf\n",
    "    for i in range(0, nnz):\n",
    "        val[i] *= df[ind[i]]\n",
    "\n",
    "    return df if copy is False else mat\n",
    "\n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm.\n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "\n",
    "    if copy is True:\n",
    "        return mat\n",
    "\n",
    "\n",
    "def grouper(input_list, n = 2):\n",
    "    for i in xrange(len(input_list) - (n - 1)):\n",
    "        yield input_list[i:i+n]\n",
    "\n",
    "def get_k_mers(input_list):\n",
    "    new_list = []\n",
    "    #new_list.extend(input_list)\n",
    "    for first, second in grouper(input_list, 2):\n",
    "        st = first + \" \"+second\n",
    "        new_list.append(st)\n",
    "\n",
    "    for first, second, third in grouper(input_list, 3):\n",
    "        st = first + \" \"+second + \" \"+third\n",
    "        new_list.append(st)\n",
    "\n",
    "    return new_list\n",
    "\n",
    "\n",
    "k = [5]\n",
    "\n",
    "k_values = k\n",
    "train_file = \"train.dat\"\n",
    "test_file=\"test.dat\"\n",
    "result_file = \"format.dat\"\n",
    "\n",
    "\n",
    "print 'Working on training set'\n",
    "print train_file\n",
    "i=0\n",
    "with open(train_file, \"r\") as fh:\n",
    "\tlines = fh.readlines()\n",
    "\ti = i + 1\n",
    "\tprint i\n",
    "\n",
    "train_labels = [int(l[:2]) for l in lines]\n",
    "print \"train_labels\"\n",
    "train_docs = [re.sub(r'[^\\w]', ' ',l[2:].lower()).split() for l in lines]\n",
    "print \"train_docs\"\n",
    "\n",
    "train_reviews_stem = [[t for t in d if len(t) >= 2 ] for d in train_docs ]\n",
    "train_reviews = [[stemmer.stem(t) for t in d ] for d in train_reviews_stem]\n",
    "print \"LOL\"\n",
    "for t in train_reviews:\n",
    "    new_list = get_k_mers(t)\n",
    "    t.extend(new_list)\n",
    "num_train_samples = len(train_reviews)\n",
    "\n",
    "print 'Working on  test file'\n",
    "with open(test_file, \"r\") as fh:\n",
    "    test_lines = fh.readlines()\n",
    "        \n",
    "    #print \"reached end of file\"\n",
    "test_docs = [re.sub(r'[^\\w]', ' ',l.lower()).split() for l in test_lines]\n",
    "#print \"test_docs done\"\n",
    "test_reviews_stem = [[t for t in d if len(t) >= 2 ] for d in test_docs]\n",
    "test_reviews = [[stemmer.stem(t) for t in d ] for d in test_reviews_stem]\n",
    "for t in test_reviews:\n",
    "    new_list = get_k_mers(t)\n",
    "    t.extend(new_list)\n",
    "num_test_samples = len(test_reviews)\n",
    "\n",
    "train_reviews.extend(test_reviews)\n",
    "\n",
    "   \n",
    "print 'Building CSR matrix'\n",
    "    # 7. Build csr_matrix with train and test reviews\n",
    "\n",
    "csr_mat = build_matrix(train_reviews)\n",
    "\n",
    "mat1 = csr_idf(csr_mat, copy=True)\n",
    "mat = csr_l2normalize(mat1, copy=True)\n",
    "\n",
    "print 'Calculate Cosine Similarity'\n",
    "similarities_sparse = cosine_similarity(mat,dense_output=False)\n",
    "\n",
    "print 'Finally, caluclating nearest neighbours'\n",
    "   \n",
    "all_test_labels = []\n",
    "for k in k_values:\n",
    "    test_labels = []\n",
    "    for test_review_index in range(num_train_samples, num_train_samples +num_test_samples):\n",
    "        similarity = similarities_sparse[test_review_index, :num_train_samples].toarray().tolist()[0]\n",
    "        similarity_with_labels = zip(similarity, train_labels, range(len(train_labels)))\n",
    "\n",
    "        sorted_similarity_with_labels = sorted(similarity_with_labels, key=lambda (val, k, l): val, reverse=True)\n",
    "           \n",
    "        tmp = 0\n",
    "\n",
    "        for j in range(k):\n",
    "            if sorted_similarity_with_labels[j][0] != 0:\n",
    "                tmp += int(sorted_similarity_with_labels[j][1])\n",
    "            if tmp == 0:\n",
    "                while tmp == 0:\n",
    "                    tmp = np.random.randint(-1,2)\n",
    "        if tmp > 0:\n",
    "            test_labels.append(1)\n",
    "            tst = 1\n",
    "        else:\n",
    "            test_labels.append(-1)\n",
    "            tst = -1\n",
    "\n",
    "    \n",
    "    all_test_labels.append(test_labels)\n",
    "\n",
    "\n",
    "result = open(result_file, 'w')\n",
    "for t in all_test_labels[0]:\n",
    "    if t == 1:\n",
    "        result.write(\"+1\")\n",
    "    else:\n",
    "        result.write(\"-1\")\n",
    "    result.write(\"\\n\")\n",
    "result.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
