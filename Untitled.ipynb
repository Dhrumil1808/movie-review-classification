{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from numpy.linalg import norm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "283111\n",
      "3809020\n",
      "25000\n",
      "284565\n",
      "3823078\n",
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t2.0\n",
      "  (0, 2)\t11.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t6.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 11)\t5.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 13)\t2.0\n",
      "  (0, 14)\t10.0\n",
      "  (0, 15)\t2.0\n",
      "  (0, 16)\t5.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 18)\t2.0\n",
      "  (0, 19)\t3.0\n",
      "  (0, 20)\t1.0\n",
      "  (0, 21)\t5.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 23)\t3.0\n",
      "  (0, 24)\t3.0\n",
      "  :\t:\n",
      "  (24999, 8605)\t1.0\n",
      "  (24999, 8820)\t1.0\n",
      "  (24999, 11329)\t1.0\n",
      "  (24999, 12415)\t1.0\n",
      "  (24999, 25642)\t1.0\n",
      "  (24999, 27378)\t1.0\n",
      "  (24999, 45854)\t1.0\n",
      "  (24999, 61695)\t1.0\n",
      "  (24999, 79788)\t1.0\n",
      "  (24999, 98345)\t1.0\n",
      "  (24999, 159758)\t1.0\n",
      "  (24999, 249269)\t1.0\n",
      "  (24999, 283098)\t1.0\n",
      "  (24999, 283099)\t1.0\n",
      "  (24999, 283100)\t1.0\n",
      "  (24999, 283101)\t1.0\n",
      "  (24999, 283102)\t1.0\n",
      "  (24999, 283103)\t1.0\n",
      "  (24999, 283104)\t1.0\n",
      "  (24999, 283105)\t1.0\n",
      "  (24999, 283106)\t1.0\n",
      "  (24999, 283107)\t1.0\n",
      "  (24999, 283108)\t1.0\n",
      "  (24999, 283109)\t1.0\n",
      "  (24999, 283110)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t11.0\n",
      "  (0, 8)\t2.0\n",
      "  (0, 9)\t2.0\n",
      "  (0, 10)\t16.0\n",
      "  (0, 11)\t1.0\n",
      "  (0, 12)\t15.0\n",
      "  (0, 13)\t1.0\n",
      "  (0, 14)\t11.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 16)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 19)\t1.0\n",
      "  (0, 20)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 23)\t5.0\n",
      "  (0, 24)\t3.0\n",
      "  :\t:\n",
      "  (24999, 15030)\t1.0\n",
      "  (24999, 15661)\t1.0\n",
      "  (24999, 16912)\t1.0\n",
      "  (24999, 20741)\t1.0\n",
      "  (24999, 23120)\t1.0\n",
      "  (24999, 23784)\t1.0\n",
      "  (24999, 26145)\t1.0\n",
      "  (24999, 26586)\t1.0\n",
      "  (24999, 26587)\t1.0\n",
      "  (24999, 28676)\t1.0\n",
      "  (24999, 31401)\t1.0\n",
      "  (24999, 33935)\t1.0\n",
      "  (24999, 46207)\t1.0\n",
      "  (24999, 48457)\t1.0\n",
      "  (24999, 49554)\t1.0\n",
      "  (24999, 50511)\t1.0\n",
      "  (24999, 52146)\t1.0\n",
      "  (24999, 66417)\t1.0\n",
      "  (24999, 68433)\t1.0\n",
      "  (24999, 75963)\t1.0\n",
      "  (24999, 84877)\t1.0\n",
      "  (24999, 115974)\t1.0\n",
      "  (24999, 178382)\t1.0\n",
      "  (24999, 284563)\t1.0\n",
      "  (24999, 284564)\t1.0\n"
     ]
    }
   ],
   "source": [
    "lines = open('train.dat')\n",
    "docs= [I.split() for I in lines]\n",
    "count = 0\n",
    "lines_test=open('test.dat')\n",
    "docs_test=[I.split() for I in lines_test]\n",
    "\n",
    "def build_matrix_train(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "    print nrows\n",
    "    print ncols\n",
    "    print nnz\n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    return mat\n",
    "\n",
    "\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )\n",
    "\n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat\n",
    "        \n",
    "def namesToMatrix(names):\n",
    "    return build_matrix(docs)\n",
    "\n",
    "\n",
    "def findNeighborsForName(name, k=1):\n",
    "    # first, find the document for the given name\n",
    "    id = -1\n",
    "    for i in range(len(names)):\n",
    "        if names[i] == name:\n",
    "            id = i\n",
    "            break\n",
    "    if id == -1:\n",
    "        print(\"Name %s not found.\" % name)\n",
    "        return []\n",
    "    # now, compute similarities of name's vector against all other name vectors\n",
    "    mat = namesToMatrix(names)\n",
    "    csr_l2normalize(mat)\n",
    "    x = mat[id,:]\n",
    "    dots = x.dot(mat.T)\n",
    "    dots[0,id] = -1 # invalidate self-similarity\n",
    "    sims = list(zip(dots.indices, dots.data))\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [names[s[0]] for s in sims[:k] if s[1] > 0 ]\n",
    "\n",
    "def splitData(mat, cls, fold=0, d=0):\n",
    "    r\"\"\" Split the matrix and class info into train and test data using d-fold hold-out\n",
    "    \"\"\"\n",
    "    n = mat.shape[0]\n",
    "    r = int(np.ceil(n*1.0/d))\n",
    "    mattr = []\n",
    "    clstr = []\n",
    "    # split mat and cls into d folds\n",
    "    for f in range(25000):\n",
    "        if f+1 != fold:\n",
    "            mattr.append( mat[f*r: min((f+1)*r, n)] )\n",
    "            clstr.extend( cls[f*r: min((f+1)*r, n)] )\n",
    "    # join all fold matrices that are not the test matrix\n",
    "    train = sp.vstack(mattr, format='csr')\n",
    "    # extract the test matrix and class values associated with the test rows\n",
    "    test = mat[(fold-1)*r: min(fold*r, n), :]\n",
    "    clste = cls[(fold-1)*r: min(fold*r, n)]\n",
    "\n",
    "    return train, clstr, test, clste\n",
    "    \n",
    "def classifyNames(names, cls, c=1, k=1, d=10):\n",
    "    r\"\"\" Classify names using c-mer frequency vector representations of the names and kNN classification with \n",
    "    cosine similarity and 10-fold cross validation\n",
    "    \"\"\"\n",
    "    lines = open('train.dat')\n",
    "    docs= [I.split() for I in lines]\n",
    "    mat = build_matrix(docs)\n",
    "    # since we're using cosine similarity, normalize the vectors\n",
    "    csr_l2normalize(mat)\n",
    "    \n",
    "    def classify(testing, training, clstr):\n",
    "        r\"\"\" Classify vector x using kNN and majority vote rule given training data and associated classes\n",
    "        \"\"\"\n",
    "        # find nearest neighbors for x\n",
    "        dots=testing.dot(training.T)\n",
    "        sims = list(zip(dots.indices, dots.data))\n",
    "        #if len(sims) == 0:\n",
    "            # could not find any neighbors\n",
    "         #   return '+' if np.random.rand() > 0.5 else '-'\n",
    "        sims.sort(key=lambda x: x[1], reverse=True)\n",
    "        tc = Counter(clstr[s[0]] for s in sims[:k]).most_common(2)\n",
    "        if len(tc) < 2 or tc[0][1] > tc[1][1]:\n",
    "            # majority vote\n",
    "            return tc[0][0]\n",
    "        # tie break\n",
    "        tc = defaultdict(float)\n",
    "        for s in sims[:k]:\n",
    "            tc[clstr[s[0]]] += s[1]\n",
    "        return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "        \n",
    "    macc = 0.0\n",
    "    for f in range(d):\n",
    "        # split data into training and testing\n",
    "        train, clstr, test, clste = splitData(mat, cls, f+1, d)\n",
    "        # predict the class of each test sample\n",
    "        clspr = [ classify(test[i,:], train, clstr) for i in range(test.shape[0]) ]\n",
    "        # compute the accuracy of the prediction\n",
    "        acc = 0.0\n",
    "        for i in range(len(clste)):\n",
    "            if clste[i] == clspr[i]:\n",
    "                acc += 1\n",
    "        acc /= len(clste)\n",
    "        macc += acc\n",
    "        \n",
    "    return macc/d\n",
    "\n",
    "def classify_result(testing, training):\n",
    "        r\"\"\" Classify vector x using kNN and majority vote rule given training data and associated classes\n",
    "        \"\"\"\n",
    "        # find nearest neighbors for x\n",
    "        distances=testing.dot(training.T)\n",
    "        sims = list(zip(dots.indices, dots.data))\n",
    "        #if len(sims) == 0:\n",
    "            # could not find any neighbors\n",
    "         #   return '+' if np.random.rand() > 0.5 else '-'\n",
    "        sims.sort(key=lambda x: x[1], reverse=True)\n",
    "        tc = Counter(clstr[s[0]] for s in sims[:k]).most_common(2)\n",
    "        if len(tc) < 2 or tc[0][1] > tc[1][1]:\n",
    "            # majority vote\n",
    "            return tc[0][0]\n",
    "        # tie break\n",
    "        tc = defaultdict(float)\n",
    "        for s in sims[:k]:\n",
    "            tc[clstr[s[0]]] += s[1]\n",
    "        return sorted(tc.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
    "        \n",
    "    \n",
    "\n",
    "def build_matrix_test(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "    print nrows\n",
    "    print ncols\n",
    "    print nnz\n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    return mat\n",
    "\n",
    "training= build_matrix_train(docs)\n",
    "testing = build_matrix_test(docs_test)\n",
    "print training\n",
    "print testing\n",
    "#print testing.dot(training.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
